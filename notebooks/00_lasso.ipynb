{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 Regression Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Overview\n",
    "    - What is a Lasso Regression?\n",
    "    - Show Me the Papers ðŸ¤”\n",
    "2. Set Up\n",
    "    - Tools\n",
    "    - Dependencies\n",
    "3. Project Structure\n",
    "4. Creating a Package\n",
    "5. Testing\n",
    "6. Building our Package\n",
    "7. Publishing our Package\n",
    "8. Serving our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll learn how to create a python package from a statistical model called, \n",
    "Lasso (or L1) Regression. The goal is not become an expert at implementing this method (I am \n",
    "confident you can master it on your own time), but rather to take seemingly challenging equation \n",
    "and bake into something others can use more than once. We'll finish the lesson by publishing \n",
    "our package, installing it, and serving a model with it.\n",
    "\n",
    "By the end of this lesson, you will have the tools to create and publish your own Python packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 What is a Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{minimize } J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j=1}^{n} |\\theta_j|$\n",
    "\n",
    "\n",
    "**Definition of Lasso Regression:**\n",
    "\n",
    "Lasso Regression, or Least Absolute Shrinkage and Selection Operator, is a linear \n",
    "regression technique that introduces a penalty term to the traditional linear \n",
    "regression objective function. This penalty term is proportional to the absolute \n",
    "values of the regression coefficients. The goal of Lasso Regression is to not only \n",
    "minimize the sum of squared errors but also to minimize the sum of the absolute \n",
    "values of the coefficients, encouraging sparsity in the model. The strength of the \n",
    "penalty is controlled by a hyperparameter, often denoted as alpha.\n",
    "\n",
    "**When to Use Lasso Regression:**\n",
    "\n",
    "Lasso Regression is particularly useful in situations where feature selection is \n",
    "important. When dealing with datasets containing a large number of features, some of \n",
    "which may be irrelevant or redundant, Lasso Regression helps by driving the coefficients \n",
    "of less informative features to exactly zero. This inherent feature selection property \n",
    "makes Lasso Regression valuable in scenarios where interpretability and a sparse model are crucial.\n",
    "\n",
    "For example, in genomics, where datasets might have thousands of genes, but only a few \n",
    "are expected to be relevant to a particular outcome, Lasso Regression can be employed to \n",
    "identify the subset of genes that play a significant role in the prediction.\n",
    "\n",
    "**When Not to Use Lasso Regression:**\n",
    "\n",
    "Lasso Regression may not be the best choice when all features in the dataset are genuinely \n",
    "informative and none should be completely eliminated. If it is important to retain all \n",
    "features without imposing sparsity, Ridge Regression, which introduces a penalty based on \n",
    "the square of the coefficients, might be a better alternative.\n",
    "\n",
    "In cases where the number of observations is significantly smaller than the number of \n",
    "features (high-dimensional data) and there is multicollinearity among the features, Lasso \n",
    "Regression might encounter challenges in selecting the most relevant features. In such \n",
    "scenarios, techniques like Ridge Regression or Elastic Net Regression, which combines L1 \n",
    "and L2 penalties, might be more suitable.\n",
    "\n",
    "**Analogy:**\n",
    "\n",
    "Think of Lasso Regression as a sculptor chiseling away excess material from a block of \n",
    "stone to reveal a refined and elegant statue. The sculptor (Lasso) carefully considers \n",
    "each part of the block (features) and decides whether it contributes meaningfully to the \n",
    "final artwork. If a part is deemed irrelevant, the sculptor chips it away, leaving only \n",
    "the essential components.\n",
    "\n",
    "In this analogy, the block of stone represents the dataset, and the sculptor's decisions \n",
    "mirror the impact of the Lasso penalty on the regression coefficients. The result is a \n",
    "streamlined and sparse model, capturing only the essential features needed for accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Show Me the Papers ðŸ¤”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(src='https://arxivxplorer.com/', width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tools We'll be Using**\n",
    "\n",
    "- [`numpy`](https://numpy.org/doc/stable/) -> \"It is a Python library that provides \n",
    "a multidimensional array object, various derived objects (such as masked arrays \n",
    "and matrices), and an assortment of routines for fast operations on arrays, including \n",
    "mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier \n",
    "transforms, basic linear algebra, basic statistical operations, random simulation and much more.\"\n",
    "- [`setuptools`](https://setuptools.pypa.io/en/latest/) -> \"Setuptools is a fully-featured, \n",
    "actively-maintained, and stable library designed to facilitate packaging Python projects.\"\n",
    "- [`build`](https://pypa-build.readthedocs.io/en/stable/) -> \"build manages \n",
    "pyproject.toml-based builds, invoking build-backend hooks as appropriate to build a \n",
    "distribution package. It is a simple build tool and does not perform any dependency management.\"\n",
    "- [`twine`](https://twine.readthedocs.io/en/latest/) -> \"Twine is a utility for publishing \n",
    "Python packages to PyPI and other repositories. It provides build system independent \n",
    "uploads of source and binary distribution artifacts for both new and existing projects.\"\n",
    "- [`pytest`](https://docs.pytest.org/en/7.4.x/) -> \"The pytest framework makes it \n",
    "easy to write small, readable tests, and can scale to support complex functional \n",
    "testing for applications and libraries.\"\n",
    "- [`mlserver`](https://mlserver.readthedocs.io/en/latest/) -> \"MLServer aims to \n",
    "provide an easy way to start serving your machine learning models through a REST \n",
    "and gRPC interface, fully compliant with KServeâ€™s V2 Dataplane spec. Watch a quick \n",
    "video introducing the project here.\"\n",
    "\n",
    "\n",
    "First open up your terminal and type the following. We'll need an virtual environment \n",
    "for all of our dependencies.\n",
    "\n",
    "```sh\n",
    "# with mamba or conda\n",
    "mamba create -n lasso_dev python=3.11\n",
    "mamba activate lasso_dev\n",
    "\n",
    "# with virtualenv\n",
    "python -m venv venv\n",
    "## for linux and mac users\n",
    "source venv/bin/activate\n",
    "## for windows users\n",
    ".\\venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "Next, we'll install a few dependencies we'll need.\n",
    "\n",
    "```sh\n",
    "pip install pandas scikit-learn numpy build twine\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of the tutorial, our project will look as follows.\n",
    "\n",
    "```md\n",
    ".\n",
    "â”œâ”€â”€ build\n",
    "â”‚   â”œâ”€â”€ bdist.linux-x86_64\n",
    "â”‚   â””â”€â”€ lib\n",
    "â”‚       â””â”€â”€ lassoreg\n",
    "â”‚           â”œâ”€â”€ __init__.py\n",
    "â”‚           â”œâ”€â”€ __pycache__\n",
    "â”‚           â”‚   â””â”€â”€ regression.cpython-311.pyc\n",
    "â”‚           â””â”€â”€ regression.py\n",
    "â”œâ”€â”€ dist\n",
    "â”‚   â”œâ”€â”€ lassoreg-0.1.0-py3-none-any.whl\n",
    "â”‚   â””â”€â”€ lassoreg-0.1.0.tar.gz\n",
    "â”œâ”€â”€ lassoreg\n",
    "â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚   â”œâ”€â”€ __pycache__\n",
    "â”‚   â”‚   â””â”€â”€ regression.cpython-311.pyc\n",
    "â”‚   â””â”€â”€ regression.py\n",
    "â”œâ”€â”€ lassoreg.egg-info\n",
    "â”‚   â”œâ”€â”€ dependency_links.txt\n",
    "â”‚   â”œâ”€â”€ PKG-INFO\n",
    "â”‚   â”œâ”€â”€ requires.txt\n",
    "â”‚   â”œâ”€â”€ SOURCES.txt\n",
    "â”‚   â””â”€â”€ top_level.txt\n",
    "â”œâ”€â”€ pyproject.toml\n",
    "â”œâ”€â”€ README.md\n",
    "â””â”€â”€ tests\n",
    "    â””â”€â”€ test_lasso.py\n",
    "```\n",
    "\n",
    "Let's start by creating a directory for our project and package, plus a few other files we'll need.\n",
    "\n",
    "\n",
    "```sh\n",
    "mkdir ../first_package ../first_package/lassoreg ../first_package/tests\n",
    "touch ../first_package/README.md ../first_package/pyproject.toml\n",
    "```\n",
    "\n",
    "Let's now get started building our package. ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading some data and going through how lasso regression works using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.load_diabetes(as_frame=True)['data'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.load_diabetes(as_frame=True)['target'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:150]\n",
    "y = y[:150]\n",
    "\n",
    "lasso = Lasso(alpha=1.0, max_iter=1000, tol=1e-4)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "print(lasso.coef_)\n",
    "print(lasso.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create our own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../first_package/lassoreg/regression.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class LassoRegression:\n",
    "    def __init__(self, alpha=1.0, max_iter=1000, tol=1e-4):\n",
    "        self.alpha = alpha  # Regularization strength\n",
    "        self.max_iter = max_iter  # Maximum number of iterations for optimization\n",
    "        self.tol = tol  # Tolerance to determine convergence\n",
    "        self.weights = None  # Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ../first_package/lassoreg/regression.py\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize coefficients with zeros\n",
    "        self.weights = np.zeros(X.shape[1] + 1)\n",
    "        X_augmented = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        cost, gradient = self._cost_and_gradient(X_augmented, y, self.weights)\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "\n",
    "            self.weights -= self.alpha * gradient\n",
    "            new_cost, new_gradient = self._cost_and_gradient(X_augmented, y, self.weights)\n",
    "            if np.abs(new_cost - cost) < self.tol:\n",
    "                break\n",
    "            cost, gradient = new_cost, new_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ../first_package/lassoreg/regression.py\n",
    "\n",
    "    def _cost_and_gradient(self, X, y, weights):\n",
    "        n_samples   = X.shape[0]\n",
    "        predictions = np.dot(X, weights)\n",
    "        residuals   = predictions - y\n",
    "        cost        = (1 / (2 * n_samples)) * np.sum(residuals**2)\n",
    "        l1_term     = self.alpha * np.sum(np.abs(weights[1:]))\n",
    "        total_cost  = cost + l1_term\n",
    "        gradient    = (1 / n_samples) * np.dot(X.T, residuals) + self.alpha * np.sign(weights)\n",
    "        gradient[0] -= self.alpha * np.sign(weights[0])  # Exclude the intercept term\n",
    "        return total_cost, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ../first_package/lassoreg/regression.py\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_augmented = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        return np.dot(X_augmented, self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoRegression:\n",
    "    def __init__(self, alpha=1.0, max_iter=1000, tol=1e-4):\n",
    "        self.alpha = alpha  # Regularization strength\n",
    "        self.max_iter = max_iter  # Maximum number of iterations for optimization\n",
    "        self.tol = tol  # Tolerance to determine convergence\n",
    "        self.weights = None  # Coefficients\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize coefficients with zeros\n",
    "        self.weights = np.zeros(X.shape[1] + 1)\n",
    "        X_augmented = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        cost, gradient = self._cost_and_gradient(X_augmented, y, self.weights)\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "\n",
    "            self.weights -= self.alpha * gradient\n",
    "            new_cost, new_gradient = self._cost_and_gradient(X_augmented, y, self.weights)\n",
    "            if np.abs(new_cost - cost) < self.tol:\n",
    "                break\n",
    "            cost, gradient = new_cost, new_gradient\n",
    "\n",
    "    def _cost_and_gradient(self, X, y, weights):\n",
    "        n_samples   = X.shape[0]\n",
    "        predictions = np.dot(X, weights)\n",
    "        residuals   = predictions - y\n",
    "        cost        = (1 / (2 * n_samples)) * np.sum(residuals**2)\n",
    "        l1_term     = self.alpha * np.sum(np.abs(weights[1:]))\n",
    "        total_cost  = cost + l1_term\n",
    "        gradient    = (1 / n_samples) * np.dot(X.T, residuals) + self.alpha * np.sign(weights)\n",
    "        gradient[0] -= self.alpha * np.sign(weights[0])  # Exclude the intercept term\n",
    "        return total_cost, gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_augmented = np.column_stack([np.ones(X.shape[0]), X])\n",
    "        return np.dot(X_augmented, self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso2 = LassoRegression(alpha=1.0, max_iter=1000, tol=1e-4)\n",
    "lasso2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso2.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso.predict(X)\n",
    "y_pred2 = lasso2.predict(X)\n",
    "y_pred[:20], y_pred2[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(y_pred - y_pred2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing is one of the most important pieces of building good software so let's add a few tests using \n",
    "`hypohesis` and `pytest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../first_package/tests/test_lasso.py\n",
    "\n",
    "import pytest\n",
    "import numpy as np\n",
    "from lassoreg.regression import LassoRegression\n",
    "from hypothesis import given, strategies as st\n",
    "\n",
    "# Example strategy for generating random data\n",
    "@st.composite\n",
    "def generate_random_data(draw):\n",
    "    n_samples = draw(st.integers(min_value=1, max_value=100))\n",
    "    n_features = draw(st.integers(min_value=1, max_value=10))\n",
    "    X = draw(st.lists(st.lists(st.floats(), min_size=n_features, max_size=n_features), min_size=n_samples, max_size=n_samples))\n",
    "    y = draw(st.lists(st.floats(), min_size=n_samples, max_size=n_samples))\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following test checks if the LassoRegression model can fit to synthetic data. It ensures \n",
    "that the weights are updated after calling the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ../first_package/tests/test_lasso.py\n",
    "\n",
    "\n",
    "def test_lasso_regression_fit():\n",
    "    # Test if the LassoRegression model can fit to synthetic data\n",
    "    X_train = np.array([[1, 2], [3, 4]])\n",
    "    y_train = np.array([5, 6])\n",
    "    model = LassoRegression(alpha=0.01, max_iter=1000, tol=1e-4)\n",
    "    model.fit(X_train, y_train)\n",
    "    assert model.weights is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This hypothesis test checks if the LassoRegression model converges with random \n",
    "data. It uses the `generate_random_data` strategy to generate random input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ../first_package/tests/test_lasso.py\n",
    "\n",
    "@given(generate_random_data())\n",
    "def test_lasso_regression_convergence(random_data):\n",
    "    # Test if the LassoRegression model converges with random data\n",
    "    X, y = random_data\n",
    "    model = LassoRegression(alpha=0.01, max_iter=1000, tol=1e-4)\n",
    "    model.fit(X, y)\n",
    "    assert model.weights is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last test checks if the `LassoRegression` model can make predictions. It sets sample \n",
    "weights for the model and asserts that predictions are not None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ../first_package/tests/test_lasso.py\n",
    "\n",
    "def test_lasso_regression_predict():\n",
    "    # Test if the LassoRegression model can make predictions\n",
    "    X_test = np.array([[1, 2]])\n",
    "    model = LassoRegression(alpha=0.01, max_iter=1000, tol=1e-4)\n",
    "    model.weights = np.array([0.5, 0.2, 0.3])  # Sample weights for testing\n",
    "    predictions = model.predict(X_test)\n",
    "    assert predictions is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building our Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our package we'll need a `pyproject.toml` file. This specification is\n",
    "\n",
    "> \"TOML, or Tom's Obvious Minimal Language, is a data serialization language designed \n",
    "for configuration files. TOML files use a simple and readable syntax, making them easy \n",
    "for humans to write and understand. TOML is often employed for configuration purposes \n",
    "in software projects, providing a structured and organized way to specify settings and \n",
    "parameters. It uses key-value pairs, arrays, and tables to represent data hierarchies, \n",
    "and its minimalistic design aims to be clear and expressive while avoiding unnecessary \n",
    "complexity. TOML files are commonly used in various applications, including project \n",
    "configuration files, package metadata, and other settings where a straightforward and \n",
    "human-readable data format is desired.\n",
    "\n",
    "The minimum configuration we'll need goes as follows.\n",
    "\n",
    "```toml\n",
    "[build-system]\n",
    "requires = [\"setuptools >= 65\", \"wheel\"]\n",
    "build-backend = \"setuptools.build_meta\"\n",
    "\n",
    "[project]\n",
    "name = \"lassoreg\"\n",
    "version = \"0.1.0\"\n",
    "dependencies = [\"numpy\"]\n",
    "```\n",
    "\n",
    "The `build-system` specifies the libraries needed to build our packages with all of its \n",
    "dependencies and configurations. The `requires` focuses on specific libraries for the build \n",
    "process and `build-backend` specifies the tool that will turn the package into binaries.\n",
    "\n",
    "the `project` section can get quite extensive but we'll leave it as is for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../first_package/pyproject.toml\n",
    "\n",
    "[build-system]\n",
    "requires = [\"setuptools >= 65\", \"wheel\"]\n",
    "build-backend = \"setuptools.build_meta\"\n",
    "\n",
    "[project]\n",
    "name = \"lassoreg\"\n",
    "version = \"0.1.0\"\n",
    "dependencies = [\"numpy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we need to do is to install our package, and we'll do so with the following \n",
    "command from within the `first_package` directory.\n",
    "\n",
    "```sh\n",
    "python -m pip install -e .\n",
    "```\n",
    "The `-m` is used to pick up a module that is already available in our environment and the `-e` \n",
    "tells python that we will be _editing_ the package as we go.\n",
    "\n",
    "Now the package is in our environment and we can test it. Open up a python or ipython session \n",
    "in your terminal and run the following.\n",
    "\n",
    "```python\n",
    "from lassoreg.regression import LassoRegression\n",
    "```\n",
    "\n",
    "Now that we know our package is working correctly, let's add a few more things to our `pyproject.toml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../first_package/pyproject.toml\n",
    "[build-system]\n",
    "requires = [\"setuptools >= 65\", \"setuptools_scm[toml]\", \"wheel\"]\n",
    "build-backend = \"setuptools.build_meta\"\n",
    "\n",
    "[project]\n",
    "name = \"lassoreg\"\n",
    "authors = [{name = \"Ramon Perez\", email = \"ramon.perez@seldon.io\"}]\n",
    "description = \"My wonderful Lasso Regression Python package\"\n",
    "version = \"0.1.0\"\n",
    "readme = \"README.md\"\n",
    "license = {text = \"MIT License\"}\n",
    "requires-python = \">=3.11\"\n",
    "dependencies = [\n",
    "    \"numpy\",\n",
    "    \"importlib_metadata\"\n",
    "]\n",
    "keywords = [\n",
    "    \"statistics\",\n",
    "    \"lasso\",\n",
    "    \"lasso regression\",\n",
    "    \"Regression\",\n",
    "    \"Model\",\n",
    "    \"Statistical Model\"\n",
    "]\n",
    "\n",
    "[project.urls]\n",
    "Source = \"https://github.com/ramonpzg/architecting_tools/first_package\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick word on versioning. Most Python packages follow the MAJOR.MINOR.PATCH and it would be useful to \n",
    "get familiarized with it. Please note, there are a few different conventions for numbering as well.\n",
    "\n",
    "- Major: A completely new version of the package where breaking changes are expected.\n",
    "- Minor: New features backwards compatible.\n",
    "- Patch: Bug fixes and improvements to code quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Publishing our Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we publish it, let's first populate the README of our project. We'll use the following paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../first_package/README.md\n",
    "\n",
    "# Lasso Regression Package\n",
    "\n",
    "[![License](https://img.shields.io/badge/license-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This Python package provides a simple implementation of Lasso Regression (L1 regularization) \n",
    "using the Python Standard Library and `NumPy`. Lasso Regression is a linear regression \n",
    "technique that adds a penalty term proportional to the absolute values of the regression \n",
    "coefficients, promoting sparsity in the model.\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install lassoreg\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "from lassoreg.regression import LassoRegression\n",
    "\n",
    "# Create an instance of Lasso Regression\n",
    "lasso_model = LassoRegression(alpha=0.01, max_iter=1000, tol=1e-4)\n",
    "\n",
    "# Fit the model to training data\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = lasso_model.predict(X_test)\n",
    "```\n",
    "\n",
    "## Documentation\n",
    "\n",
    "For detailed information on the parameters and methods, please refer to the docstring in the source code.\n",
    "\n",
    "## Example\n",
    "\n",
    "An example of generating synthetic data and fitting the Lasso Regression model is provided in the `example` directory.\n",
    "\n",
    "```bash\n",
    "cd example\n",
    "python example.py\n",
    "```\n",
    "\n",
    "## Testing\n",
    "\n",
    "To run the unit tests, use the following command:\n",
    "\n",
    "```bash\n",
    "pytest tests\n",
    "```\n",
    "\n",
    "## License\n",
    "\n",
    "This package is licensed under the [MIT License](LICENSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to install `build` and `twine` to create our package and publish it.\n",
    "\n",
    "```sh\n",
    "pip install build twine\n",
    "```\n",
    "\n",
    "Let's first build our package form the main directory of our package.\n",
    "\n",
    "```sh\n",
    "python -m build\n",
    "```\n",
    "\n",
    "You'll see a new directory called `dist` and in it, you'll see two files, a `.whl` and a `.tar.gz`. Here \n",
    "is some additional information about the two.\n",
    "\n",
    "1. Wheel (`.whl`) Package:\n",
    "    - Purpose: The Wheel format is a binary distribution format that aims to be more efficient \n",
    "    for installing Python packages compared to the traditional source distribution formats like .tar.gz.\n",
    "    - Advantages:\n",
    "        - Faster installation: Wheels are pre-compiled, making installation faster compared to source distributions.\n",
    "        - Simplified package management: Wheels include metadata and dependencies, streamlining the installation process.\n",
    "        - Platform-specific: Wheels can be platform-specific, optimizing compatibility with different systems.\n",
    "    - Use Case: Wheels are commonly used for distributing and installing Python packages, especially for projects with binary extensions or dependencies.\n",
    "2. Source Tarball (`.tar.gz`) Package:\n",
    "    - Purpose: The source tarball is a compressed archive of the project's source code and related files. It contains everything needed to build and install the project.\n",
    "    - Advantages:\n",
    "        - Portability: Source tarballs can be used on any platform, as they provide the project's source code.\n",
    "        - Customization: Users can modify the source code before building and installing the package.\n",
    "    - Use Case: Source tarballs are often used when distributing open-source projects, allowing users to build and install the software on their system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publishing to GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing about `pip` is that it allows us to install a project directly from a repo or \n",
    "and `tarball`. While either of these two options can be quite slow due to the whole repo \n",
    "being contained in the download, they can still be quite useful for working with packages \n",
    "that haven't been published or features in different branches. Let's walk over the options.\n",
    "\n",
    "Note: These examples are borrowed from the excellent tutorial on packaging by \n",
    "[The Carpentries](https://carpentries.org), and you can find it \n",
    "[here](https://carpentries-incubator.github.io/python_packaging/instructor/05-publishing.html).\n",
    "\n",
    "```sh\n",
    "pip install \"git+https://github.com/ramonpzg/architecing_tools\"\n",
    "pip install \"git+https://github.com/ramonpzg/architecing_tools@1.2.3\"\n",
    "pip install \"git+https://github.com/ramonpzg/architecing_tools@branch\"\n",
    "pip install \"git+https://github.com/ramonpzg/architecing_tools@1a2b3c4\"\n",
    "pip install \"https://github.com/ramonpzg/architecing_tools/archive/1.2.3.zip\"\n",
    "```\n",
    "\n",
    "you can also add them all to your dependencies in your pyproject.toml\n",
    "\n",
    "```py\n",
    "dependencies = [\n",
    "    \"mypkg @ https://github.com/user/ramonpzg/architecing_tools/1.2.3.zip\",\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publishing to PyPi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will first need to create an account at [pypi.org](https://pypi.org), authenticate your \n",
    "account\n",
    "\n",
    "Go to the website.  \n",
    "![pypi1](../images/pypi1.png)\n",
    "\n",
    "Create an account.  \n",
    "![pypi2](../images/pypi2.png)\n",
    "\n",
    "Enable two-factor authentication (Optional but recommended).  \n",
    "![pypi3](../images/pypi3.png)\n",
    "\n",
    "Once you finish creating your account, you will need to create an API token by going \n",
    "to **manage** >> **account** and then to the following section.\n",
    "\n",
    "![pypi4](../images/pypi4.png)\n",
    "\n",
    "Once you have your API token, create a file called `.pypirc` in your home directory and then add \n",
    "the following lines.\n",
    "\n",
    "```sh\n",
    "[pypi]\n",
    "  username = __token__\n",
    "  password = your_api_token\n",
    "```\n",
    "\n",
    "Perfect, now we're ready to publish our package, but first, let's check that there are no issues \n",
    "with the wheels and the tarball we created with our package.\n",
    "\n",
    "```sh\n",
    "twine check dist/*\n",
    "```\n",
    "\n",
    "And, for the last step.\n",
    "\n",
    "```sh\n",
    "twine upload dist/*\n",
    "```\n",
    "\n",
    "![pypi5](../images/pypi5.png)\n",
    "\n",
    "Excellent, we have successfully uploaded our package and can now install it via pip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Serving our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the steps we'll be taking in this section.\n",
    "\n",
    "1. Download Library\n",
    "2. Train Model\n",
    "3. Save Pickle File\n",
    "4. Serve it\n",
    "5. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lassoreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso3 = LassoRegression(alpha=1.0, max_iter=1000, tol=1e-4)\n",
    "lasso3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/model.pkl', 'wb') as f:\n",
    "    pickle.dump(lasso3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso3 = pickle.load(open('../models/model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0, None].shape, X[0, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso3.predict(X[0, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do it in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = pickle.load(open('../server/models/model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../server/my_lasso.py\n",
    "\n",
    "from mlserver.codecs import decode_args\n",
    "from mlserver.utils import get_model_uri\n",
    "from mlserver import MLModel\n",
    "from lassoreg.regression import LassoRegression\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "class LassoCLS(MLModel):\n",
    "    async def load(self) -> bool:\n",
    "        X, y = datasets.load_diabetes(return_X_y=True)\n",
    "        X = X[:150]\n",
    "        y = y[:150]\n",
    "        self.model = LassoRegression(alpha=1.0, max_iter=1000, tol=1e-4)\n",
    "        self.model.fit(X, y)\n",
    "        return True\n",
    "\n",
    "    @decode_args\n",
    "    async def predict(self, features: np.ndarray) -> np.ndarray:\n",
    "        return self.model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../server/model-settings.json\n",
    "{\n",
    "    \"name\": \"lasso_service\",\n",
    "    \"implementation\": \"my_lasso.LassoCLS\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../server/settings.json\n",
    "{\n",
    "    \"http_port\": 7090,\n",
    "    \"grpc_port\": 7050,\n",
    "    \"metrics_port\": 9090\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the files needed for our service, we can run the following line to start our server.\n",
    "```sh\n",
    "mlserver start name_of_directory\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlserver.codecs import NumpyCodec\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"http://localhost:7090/v2/models/lasso_service/infer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = X[0, None]\n",
    "inference_request = {\n",
    "    'inputs': [\n",
    "        NumpyCodec.encode_input(name=\"features\", payload=x_0).dict()\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "print(response)\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

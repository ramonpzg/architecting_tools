{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Packaging a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Overview\n",
    "2. Package\n",
    "3. Instructions\n",
    "4. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using this package in a little bit.\n",
    "\n",
    "```py\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        unique_classes = np.unique(y)\n",
    "\n",
    "        # Base cases\n",
    "        if len(unique_classes) == 1:\n",
    "            # If all labels are the same, create a leaf node\n",
    "            return {'class': unique_classes[0]}\n",
    "\n",
    "        if self.max_depth is not None and depth == self.max_depth:\n",
    "            # If max depth is reached, create a leaf node with the majority class\n",
    "            majority_class = np.argmax(np.bincount(y))\n",
    "            return {'class': majority_class}\n",
    "\n",
    "        # Find the best split\n",
    "        best_split = self._find_best_split(X, y)\n",
    "\n",
    "        if best_split is None:\n",
    "            # If no split improves purity, create a leaf node with the majority class\n",
    "            majority_class = np.argmax(np.bincount(y))\n",
    "            return {'class': majority_class}\n",
    "\n",
    "        feature_index, threshold = best_split\n",
    "\n",
    "        # Split the data\n",
    "        left_indices = X[:, feature_index] <= threshold\n",
    "        right_indices = ~left_indices\n",
    "\n",
    "        # Recursively build left and right subtrees\n",
    "        left_subtree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "        right_subtree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "\n",
    "        # Return a node representing the split\n",
    "        return {'feature_index': feature_index, 'threshold': threshold,\n",
    "                'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        num_features = X.shape[1]\n",
    "        best_gini = float('inf')\n",
    "        best_split = None\n",
    "\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = np.unique(X[:, feature_index])\n",
    "            for value in feature_values:\n",
    "                left_indices = X[:, feature_index] <= value\n",
    "                right_indices = ~left_indices\n",
    "\n",
    "                gini = self._calculate_gini_index(y[left_indices], y[right_indices])\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_split = (feature_index, value)\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    def _calculate_gini_index(self, left_labels, right_labels):\n",
    "        total_size = len(left_labels) + len(right_labels)\n",
    "\n",
    "        if total_size == 0:\n",
    "            return 0\n",
    "\n",
    "        p_left = len(left_labels) / total_size\n",
    "        p_right = len(right_labels) / total_size\n",
    "\n",
    "        gini_left = 1 - np.sum((np.bincount(left_labels) / len(left_labels))**2)\n",
    "        gini_right = 1 - np.sum((np.bincount(right_labels) / len(right_labels))**2)\n",
    "\n",
    "        gini_index = p_left * gini_left + p_right * gini_right\n",
    "\n",
    "        return gini_index\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_tree(self.tree, x) for x in X])\n",
    "\n",
    "    def _predict_tree(self, node, x):\n",
    "        if 'class' in node:\n",
    "            # If it's a leaf node, return the predicted class\n",
    "            return node['class']\n",
    "        else:\n",
    "            # Traverse the tree recursively\n",
    "            if x[node['feature_index']] <= node['threshold']:\n",
    "                return self._predict_tree(node['left'], x)\n",
    "            else:\n",
    "                return self._predict_tree(node['right'], x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- install pipx\n",
    "- install pdm\n",
    "- pdm\n",
    "- mkdir second_package\n",
    "- cd second_package\n",
    "- pdm init\n",
    "    - 0\n",
    "    - y\n",
    "    - y\n",
    "    - decision_tree\n",
    "    - default\n",
    "    - description\n",
    "    - pdm-backend\n",
    "    - MIT\n",
    "    - Author default\n",
    "    - Email default\n",
    "    - default\n",
    "        * walk through the output\n",
    "        - go to pyproject.toml and show that there are no dependencies\n",
    "        - use pdm add for numpy\n",
    "        - use pdm install\n",
    "    - explain differences between using src and the name of the package\n",
    "- Create decision tree file\n",
    "- add decision tree step by step\n",
    "- test scikit-learn implementation\n",
    "- test our from-scratch implementation\n",
    "- create unit tests\n",
    "- add repo url to toml\n",
    "- add to github with tag\n",
    "- pdm build\n",
    "- pdm publish --no-build\n",
    "- go to pypi and look for package\n",
    "- install it and use it to test it\n",
    "    - create env\n",
    "    - activate env\n",
    "    - pip install package ipython scikit-learn\n",
    "    - open ipython\n",
    "        from sklearn.datasets import make_classification\n",
    "        from decision_tree.classification import DecisionTreeClassifier\n",
    "        X, y = make_classification(1000, 10, random_state=0)\n",
    "        dt_classifier = DecisionTreeClassifier(max_depth=3)\n",
    "        dt_classifier.fit(X, y)\n",
    "        predictions = dt_classifier.predict(X)\n",
    "        predictions\n",
    "- add some more functionality\n",
    "- install it in a new env \n",
    "- train a model\n",
    "- load it and test it with MLServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../second_package/tests/test_decisions.py\n",
    "\n",
    "import pytest\n",
    "import numpy as np\n",
    "from decision_tree_classifier import DecisionTreeClassifier\n",
    "from hypothesis import given, strategies as st\n",
    "\n",
    "# Example strategy for generating random data\n",
    "@st.composite\n",
    "def generate_random_data(draw):\n",
    "    n_samples = draw(st.integers(min_value=1, max_value=100))\n",
    "    n_features = draw(st.integers(min_value=1, max_value=10))\n",
    "    X = draw(st.lists(st.lists(st.floats(), min_size=n_features, max_size=n_features), min_size=n_samples, max_size=n_samples))\n",
    "    y = draw(st.lists(st.integers(), min_size=n_samples, max_size=n_samples))\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ../second_package/tests/test_decisions.py\n",
    "\n",
    "def test_decision_tree_classifier_fit():\n",
    "    # Test if the DecisionTreeClassifier model can fit to synthetic data\n",
    "    X_train = np.array([[1, 2], [3, 4]])\n",
    "    y_train = np.array([0, 1])\n",
    "    model = DecisionTreeClassifier(max_depth=3)\n",
    "    model.fit(X_train, y_train)\n",
    "    assert model.tree is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ../second_package/tests/test_decisions.py\n",
    "\n",
    "@given(generate_random_data())\n",
    "def test_decision_tree_classifier_predict(random_data):\n",
    "    # Test if the DecisionTreeClassifier model can make predictions with random data\n",
    "    X, y = random_data\n",
    "    model = DecisionTreeClassifier(max_depth=3)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Ensure predictions are valid\n",
    "    predictions = model.predict(X)\n",
    "    assert all(isinstance(pred, int) for pred in predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a ../second_package/tests/test_decisions.py\n",
    "\n",
    "def test_decision_tree_classifier_max_depth():\n",
    "    # Test if the DecisionTreeClassifier respects the max_depth parameter\n",
    "    X_train = np.array([[1, 2], [3, 4]])\n",
    "    y_train = np.array([0, 1])\n",
    "    model = DecisionTreeClassifier(max_depth=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Ensure the tree depth does not exceed the specified max_depth\n",
    "    def get_tree_depth(node):\n",
    "        if 'class' in node:\n",
    "            return 1\n",
    "        else:\n",
    "            return 1 + max(get_tree_depth(node['left']), get_tree_depth(node['right']))\n",
    "    \n",
    "    assert get_tree_depth(model.tree) <= model.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run `pytest tests` to make sure that our code is solid."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synth_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
